{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from lxml import etree\n",
    "import pandas as pd\n",
    "import time\n",
    "import random\n",
    "\n",
    "data_id = []\n",
    "data_star = []\n",
    "data_date = []\n",
    "data_comment = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scraping_page(start, l1, l2, l3, l4, code = \"35465232\"):\n",
    "    url = f\"https://movie.douban.com/subject/{code}/comments?start={start}\"\n",
    "    headers = {\n",
    "        \"Accept\": \"text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,image/apng,*/*;q=0.8\",\n",
    "        \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/63.0.3239.132 Safari/537.36\"\n",
    "        }\n",
    "    \n",
    "    try:\n",
    "        response = requests.get(url, headers = headers)\n",
    "        response.raise_for_status()\n",
    "        time.sleep(random.randint(5,10))\n",
    "\n",
    "        parser = etree.HTMLParser() # 创建HTML解析器对象，默认配置\n",
    "        tree = etree.fromstring(response.text, parser) # 使用上面的解析器解析网页内容\n",
    "        # 也可以用tree = etree.HTML(response.text)，默认使用HTMLParser解析\n",
    "        divs = tree.xpath('//div[@class = \"comment\"]')\n",
    "        for div in divs:\n",
    "            id = div.xpath('./h3/span[@class = \"comment-info\"]/a/text()')[0]\n",
    "            star = div.xpath('./h3/span[@class = \"comment-info\"]/span')[1].get(\"class\")[7]\n",
    "            date = div.xpath('./h3//span[@class = \"comment-time \"]/text()')[0].strip()\n",
    "            comment = div.xpath('.//span[@class = \"short\"]/text()')[0]\n",
    "            l1.append(id)\n",
    "            l2.append(star)\n",
    "            l3.append(date)\n",
    "            l4.append(comment)\n",
    "        print(f\"{start + 1} to {start + 20} done!\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Failed! {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for start in range(0, 100, 20):\n",
    "    scraping_page(start, data_id, data_star, data_date, data_comment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    data = {\n",
    "        '用户名': data_id,\n",
    "        '评分': data_star,\n",
    "        '日期': data_date,\n",
    "        '评论': data_comment\n",
    "    }\n",
    "    df = pd.DataFrame(data)\n",
    "    df.to_excel('douban_comments.xlsx', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tkhconda",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
